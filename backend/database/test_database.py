"""
æ•°æ®åº“åŠŸèƒ½æµ‹è¯•è„šæœ¬
Database functionality test script
"""
import os
import sys
from pathlib import Path
import asyncio
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from . import (
    init_database, 
    check_database_connection,
    ScheduledTaskDAO,
    ResearchHistoryDAO,
    TrendDataDAO,
    AnalyticsDAO
)
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_database_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    logger.info("Testing database connection...")
    return check_database_connection()


def test_task_operations():
    """æµ‹è¯•å®šæ—¶ä»»åŠ¡æ“ä½œ"""
    logger.info("Testing scheduled task operations...")
    
    try:
        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
        task_data = {
            "topic": "æµ‹è¯•è¯é¢˜ï¼šAIå‘å±•è¶‹åŠ¿",
            "keywords": ["AI", "æœºå™¨å­¦ä¹ ", "æŠ€æœ¯è¶‹åŠ¿"],
            "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ä»»åŠ¡",
            "interval_hours": 6,
            "analysis_depth": "basic",
            "source_types": ["news", "academic"],
            "report_type": "research_report",
            "report_source": "web",
            "tone": "objective"
        }
        
        # åˆ›å»ºä»»åŠ¡
        task = ScheduledTaskDAO.create_task(task_data)
        logger.info(f"âœ… Created task: {task.id}")
        
        # è·å–ä»»åŠ¡
        retrieved_task = ScheduledTaskDAO.get_task_by_id(task.id)
        assert retrieved_task is not None, "Failed to retrieve created task"
        logger.info(f"âœ… Retrieved task: {retrieved_task.topic}")
        
        # æ›´æ–°ä»»åŠ¡
        update_data = {"description": "æ›´æ–°åçš„æè¿°", "interval_hours": 12}
        updated_task = ScheduledTaskDAO.update_task(task.id, update_data)
        assert updated_task.description == "æ›´æ–°åçš„æè¿°", "Failed to update task"
        logger.info(f"âœ… Updated task description")
        
        # è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨
        user_tasks = ScheduledTaskDAO.get_tasks_by_user("default_user")
        assert len(user_tasks) >= 1, "Failed to get user tasks"
        logger.info(f"âœ… Found {len(user_tasks)} user tasks")
        
        # æµ‹è¯•å¾…æ‰§è¡Œä»»åŠ¡æŸ¥è¯¢
        pending_tasks = ScheduledTaskDAO.get_pending_tasks()
        logger.info(f"âœ… Found {len(pending_tasks)} pending tasks")
        
        return task.id
        
    except Exception as e:
        logger.error(f"âŒ Task operations test failed: {e}")
        raise


def test_research_history_operations(task_id: str):
    """æµ‹è¯•ç ”ç©¶å†å²æ“ä½œ"""
    logger.info("Testing research history operations...")
    
    try:
        # åˆ›å»ºæµ‹è¯•å†å²è®°å½•
        history_data = {
            "task_id": task_id,
            "raw_result": "è¿™æ˜¯æµ‹è¯•çš„ç ”ç©¶ç»“æœå†…å®¹...",
            "summary": "è¿™æ˜¯AIç”Ÿæˆçš„æ‘˜è¦",
            "key_findings": ["å‘ç°1", "å‘ç°2", "å‘ç°3"],
            "key_changes": ["å˜åŒ–1", "å˜åŒ–2"],
            "sources_count": 5,
            "tokens_used": 1500,
            "trend_score": 7.5,
            "sentiment_score": 0.3,
            "status": "success"
        }
        
        # åˆ›å»ºå†å²è®°å½•
        history = ResearchHistoryDAO.create_history(history_data)
        logger.info(f"âœ… Created research history: {history.id}")
        
        # è·å–ä»»åŠ¡å†å²
        task_histories = ResearchHistoryDAO.get_history_by_task(task_id)
        assert len(task_histories) >= 1, "Failed to get task histories"
        logger.info(f"âœ… Found {len(task_histories)} histories for task")
        
        # è·å–æœ€æ–°å†å²
        latest_history = ResearchHistoryDAO.get_latest_history(task_id)
        assert latest_history is not None, "Failed to get latest history"
        logger.info(f"âœ… Retrieved latest history: {latest_history.summary}")
        
        # æ›´æ–°å†å²è®°å½•
        update_data = {"summary": "æ›´æ–°åçš„æ‘˜è¦", "trend_score": 8.0}
        updated_history = ResearchHistoryDAO.update_history(history.id, update_data)
        assert updated_history.trend_score == 8.0, "Failed to update history"
        logger.info(f"âœ… Updated history trend score to {updated_history.trend_score}")
        
        return history.id
        
    except Exception as e:
        logger.error(f"âŒ Research history operations test failed: {e}")
        raise


def test_trend_data_operations(task_id: str):
    """æµ‹è¯•è¶‹åŠ¿æ•°æ®æ“ä½œ"""
    logger.info("Testing trend data operations...")
    
    try:
        # åˆ›å»ºæµ‹è¯•è¶‹åŠ¿æ•°æ®
        trend_data = {
            "task_id": task_id,
            "period_start": datetime.now() - timedelta(days=1),
            "period_end": datetime.now(),
            "keyword_trends": {
                "AI": 8.5,
                "æœºå™¨å­¦ä¹ ": 7.2,
                "æŠ€æœ¯è¶‹åŠ¿": 6.8
            },
            "sentiment_changes": {
                "positive": 0.6,
                "neutral": 0.3,
                "negative": 0.1
            },
            "new_topics": ["é‡å­è®¡ç®—", "è¾¹ç¼˜AI"],
            "emerging_keywords": ["é‡å­AI", "è¾¹ç¼˜è®¡ç®—"],
            "activity_level": 8.0,
            "change_magnitude": 6.5,
            "confidence_score": 0.85
        }
        
        # åˆ›å»ºè¶‹åŠ¿æ•°æ®
        trend = TrendDataDAO.create_trend_data(trend_data)
        logger.info(f"âœ… Created trend data: {trend.id}")
        
        # è·å–ä»»åŠ¡è¶‹åŠ¿æ•°æ®
        task_trends = TrendDataDAO.get_trend_data_by_task(task_id)
        assert len(task_trends) >= 1, "Failed to get task trends"
        logger.info(f"âœ… Found {len(task_trends)} trend data for task")
        
        # è·å–æœ€æ–°è¶‹åŠ¿æ•°æ®
        latest_trend = TrendDataDAO.get_latest_trend_data(task_id)
        assert latest_trend is not None, "Failed to get latest trend"
        logger.info(f"âœ… Retrieved latest trend: activity_level={latest_trend.activity_level}")
        
        return trend.id
        
    except Exception as e:
        logger.error(f"âŒ Trend data operations test failed: {e}")
        raise


def test_analytics_operations(task_id: str):
    """æµ‹è¯•åˆ†æç»Ÿè®¡æ“ä½œ"""
    logger.info("Testing analytics operations...")
    
    try:
        # è·å–ä»»åŠ¡ç»Ÿè®¡
        task_stats = AnalyticsDAO.get_task_statistics(task_id)
        assert "task_info" in task_stats, "Failed to get task statistics"
        logger.info(f"âœ… Task statistics: {task_stats['total_executions']} executions")
        
        # è·å–ç”¨æˆ·ç»Ÿè®¡
        user_stats = AnalyticsDAO.get_user_statistics("default_user")
        assert "total_tasks" in user_stats, "Failed to get user statistics"
        logger.info(f"âœ… User statistics: {user_stats['total_tasks']} tasks")
        
    except Exception as e:
        logger.error(f"âŒ Analytics operations test failed: {e}")
        raise


def cleanup_test_data(task_id: str):
    """æ¸…ç†æµ‹è¯•æ•°æ®"""
    logger.info("Cleaning up test data...")
    
    try:
        # åˆ é™¤æµ‹è¯•ä»»åŠ¡ï¼ˆä¼šçº§è”åˆ é™¤ç›¸å…³æ•°æ®ï¼‰
        success = ScheduledTaskDAO.delete_task(task_id)
        if success:
            logger.info("âœ… Test data cleaned up successfully")
        else:
            logger.warning("âš ï¸ Failed to clean up test data")
            
    except Exception as e:
        logger.error(f"âŒ Cleanup failed: {e}")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ Starting database functionality tests...")
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        logger.info("Initializing database...")
        init_database()
        
        # æµ‹è¯•æ•°æ®åº“è¿æ¥
        if not test_database_connection():
            raise Exception("Database connection test failed")
        
        # æµ‹è¯•ä»»åŠ¡æ“ä½œ
        task_id = test_task_operations()
        
        # æµ‹è¯•ç ”ç©¶å†å²æ“ä½œ
        history_id = test_research_history_operations(task_id)
        
        # æµ‹è¯•è¶‹åŠ¿æ•°æ®æ“ä½œ
        trend_id = test_trend_data_operations(task_id)
        
        # æµ‹è¯•åˆ†æç»Ÿè®¡æ“ä½œ
        test_analytics_operations(task_id)
        
        logger.info("ğŸ‰ All database tests passed successfully!")
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†æµ‹è¯•æ•°æ®
        cleanup = os.getenv("CLEANUP_TEST_DATA", "true").lower() == "true"
        if cleanup:
            cleanup_test_data(task_id)
        
        return True
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Database tests failed: {e}")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    if not success:
        sys.exit(1)
